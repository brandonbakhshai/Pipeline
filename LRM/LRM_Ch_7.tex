\documentclass[./LRM_main.tex]{subfiles}
\begin{comment}
If you want a box around your answer and that answer is an
equation then use \boxed{$$ equation $$} 

if you want to indent a block of text:
\begin{adjustwidth}{cm of right indent}{cm of left indent}
% paragraph to be indented
\end{adjustwidth}

if you just want one indent for one line 
use \indent per intended indent per line

A sections numbers automatically, so if the number of 
the problem is out of order it would be easier to 
just indent and bold the sections and subsections
and not use the \section{} kind of commands

\newpage makes a new page

$normal math mode$
$$Special math mode$$

to include an image use
\includegraphics{image_name}
image_name is the file name (.png) without the extension. The file
name cannot have any spaces or any periods other than the one before
the file extension.

To include a codeblock use
\begin{lstlisting}
ExampleCode(blah, blah)
{
	it does tabbing and everything;
	for (coloring of major languages like java){
		add the folloing to the \lstset tuple:
			language=<name_of_language>;
	}
}
\end{lstlisting}

\end{comment}


\begin{document}

%\tableofcontents

%\thispagestyle{empty}
%\newpage
% If you want to change how the subsubsection's are numbered
%\renewcommand{\thesubsection}{\thesection.\alph{subsection}.} 

%\setcounter{page}{0}
\chapter{Asynchronous Programming with Pipeline}
Async control flow is incredibly useful when dealing with I/O operations, which are the foundation of web-based programming. When restricted to a single-threaded and single-process model, I/O operations in a programming language are blocking and a program can wait for an unbounded time. Introduce multi-threading or multi-process models, and a programming language becomes much more complex. The single-threaded asynchronous control flow model simplifies dealing with I/O operations such that the program does not halt because of them.


\section{My First Pipeline}
Consider the following example pipeline:

\begin{lstlisting}
readFile('/home/user/you/data.txt') 
| processData(_) 
| saveProcessedData(_, '/home/user/you/processedData.txt')
\end{lstlisting}
Formally, the definition of a pipeline is as such:
\begin{lstlisting}
function0(Type param0, ..., Type paramN) | 
function1(_, Type param0, ..., Type paramN) | 
function2(_, Type param0, ..., Type paramN) | ... | 
functionN(_, Type param0, ..., Type paramN)
\end{lstlisting}
How to interpret the above:
"Type" references some actual type
"Type param1, ..., Type paramN" references some (potentially zero-length) sequence of parameters to a function "\_" acts as a placeholder for whatever value will be provided by the function one to the left in the pipeline

\begin{adjustwidth}{1cm}{2cm}
Note that:\\
The first function in the pipeline, function0, has no placeholder "\_" because it has no function one to the left from which to take a value.
The sequence of parameters can be of any finite length, including zero.
\end{adjustwidth}
\section{And Then There Were Two}

Consider the terms "pipelineX" to refer to a sequence of functions arranged in a pipeline as detailed in the section "My First Pipeline," where X is a number serving as a unique ID for the pipeline. Now consider the two distinct pipelines, "pipeline0" and "pipeline1." Both pipelines contain functions which are blocking, waiting for the results of an I/O operation. The two pipelines are arranged as such in code:
\begin{lstlisting}
pipeline0;
pipeline1;
\end{lstlisting}
Let's mimic the flow of a real program as it executes the two lines above. "Pipeline0" is executed and runs until there is a blocking operation. As soon as a blocking operation is encountered, the program moves it off to a worker thread, and then on the main thread continues on to execute "pipeline1."  

Now we have a handful of different cases to consider.



\section{Brief Summary of the Architecture?}
Functions in a pipeline do not return. Rather, an entire pipeline may be thought of a series of nested functions, where what might be mistaken for the return value is simply passed as a parameter to the next nested function, and so on. 

Therefore, if there is data you wish to manipulate or use after a function yields it, this manipulation/use should be done within the same pipeline.

The same state is kept throughout an entire pipeline

This is some text

\end{document}

